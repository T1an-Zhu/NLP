{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9501187648456056,
  "eval_steps": 200,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011876484560570071,
      "grad_norm": 2.9633121490478516,
      "learning_rate": 4.941805225653207e-05,
      "loss": 0.7095,
      "step": 50
    },
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 2.2679765224456787,
      "learning_rate": 4.882422802850357e-05,
      "loss": 0.6883,
      "step": 100
    },
    {
      "epoch": 0.035629453681710214,
      "grad_norm": 1.170799732208252,
      "learning_rate": 4.823040380047506e-05,
      "loss": 0.678,
      "step": 150
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 2.6607348918914795,
      "learning_rate": 4.763657957244656e-05,
      "loss": 0.6211,
      "step": 200
    },
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 3.1171183586120605,
      "learning_rate": 4.704275534441806e-05,
      "loss": 0.4368,
      "step": 250
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 6.3434038162231445,
      "learning_rate": 4.644893111638955e-05,
      "loss": 0.3696,
      "step": 300
    },
    {
      "epoch": 0.0831353919239905,
      "grad_norm": 4.621149063110352,
      "learning_rate": 4.585510688836105e-05,
      "loss": 0.361,
      "step": 350
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 3.2358016967773438,
      "learning_rate": 4.5261282660332544e-05,
      "loss": 0.3489,
      "step": 400
    },
    {
      "epoch": 0.10688836104513064,
      "grad_norm": 3.7816596031188965,
      "learning_rate": 4.466745843230404e-05,
      "loss": 0.3444,
      "step": 450
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 5.88822078704834,
      "learning_rate": 4.407363420427554e-05,
      "loss": 0.3627,
      "step": 500
    },
    {
      "epoch": 0.13064133016627077,
      "grad_norm": 3.176765203475952,
      "learning_rate": 4.347980997624703e-05,
      "loss": 0.3455,
      "step": 550
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.9326164722442627,
      "learning_rate": 4.2885985748218525e-05,
      "loss": 0.3725,
      "step": 600
    },
    {
      "epoch": 0.1543942992874109,
      "grad_norm": 2.502739429473877,
      "learning_rate": 4.2292161520190026e-05,
      "loss": 0.324,
      "step": 650
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 1.956478476524353,
      "learning_rate": 4.169833729216152e-05,
      "loss": 0.305,
      "step": 700
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 6.568281650543213,
      "learning_rate": 4.110451306413302e-05,
      "loss": 0.3137,
      "step": 750
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 3.9533088207244873,
      "learning_rate": 4.051068883610451e-05,
      "loss": 0.3322,
      "step": 800
    },
    {
      "epoch": 0.20190023752969122,
      "grad_norm": 3.436654567718506,
      "learning_rate": 3.991686460807601e-05,
      "loss": 0.3584,
      "step": 850
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 6.310741424560547,
      "learning_rate": 3.932304038004751e-05,
      "loss": 0.368,
      "step": 900
    },
    {
      "epoch": 0.22565320665083136,
      "grad_norm": 8.481409072875977,
      "learning_rate": 3.872921615201901e-05,
      "loss": 0.3178,
      "step": 950
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 6.061875820159912,
      "learning_rate": 3.81353919239905e-05,
      "loss": 0.2952,
      "step": 1000
    },
    {
      "epoch": 0.2494061757719715,
      "grad_norm": 5.98911714553833,
      "learning_rate": 3.7541567695962e-05,
      "loss": 0.2971,
      "step": 1050
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 5.37204647064209,
      "learning_rate": 3.6947743467933495e-05,
      "loss": 0.3074,
      "step": 1100
    },
    {
      "epoch": 0.27315914489311166,
      "grad_norm": 1.9326828718185425,
      "learning_rate": 3.635391923990499e-05,
      "loss": 0.2878,
      "step": 1150
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 8.803457260131836,
      "learning_rate": 3.576009501187649e-05,
      "loss": 0.2677,
      "step": 1200
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 3.019080400466919,
      "learning_rate": 3.516627078384798e-05,
      "loss": 0.3023,
      "step": 1250
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 6.839130878448486,
      "learning_rate": 3.4572446555819476e-05,
      "loss": 0.3227,
      "step": 1300
    },
    {
      "epoch": 0.32066508313539194,
      "grad_norm": 3.1014244556427,
      "learning_rate": 3.397862232779098e-05,
      "loss": 0.3021,
      "step": 1350
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 6.587950229644775,
      "learning_rate": 3.338479809976247e-05,
      "loss": 0.2801,
      "step": 1400
    },
    {
      "epoch": 0.34441805225653205,
      "grad_norm": 4.938969612121582,
      "learning_rate": 3.279097387173397e-05,
      "loss": 0.2776,
      "step": 1450
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 10.20982837677002,
      "learning_rate": 3.2197149643705464e-05,
      "loss": 0.3175,
      "step": 1500
    },
    {
      "epoch": 0.3681710213776722,
      "grad_norm": 5.059764862060547,
      "learning_rate": 3.160332541567696e-05,
      "loss": 0.306,
      "step": 1550
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 2.5316545963287354,
      "learning_rate": 3.100950118764846e-05,
      "loss": 0.2569,
      "step": 1600
    },
    {
      "epoch": 0.3919239904988123,
      "grad_norm": 3.282062292098999,
      "learning_rate": 3.0415676959619955e-05,
      "loss": 0.3101,
      "step": 1650
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 5.309618949890137,
      "learning_rate": 2.982185273159145e-05,
      "loss": 0.2775,
      "step": 1700
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 6.252610683441162,
      "learning_rate": 2.922802850356295e-05,
      "loss": 0.2765,
      "step": 1750
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 6.37428617477417,
      "learning_rate": 2.8634204275534443e-05,
      "loss": 0.2844,
      "step": 1800
    },
    {
      "epoch": 0.43942992874109266,
      "grad_norm": 6.851111888885498,
      "learning_rate": 2.8040380047505936e-05,
      "loss": 0.3075,
      "step": 1850
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 2.2336902618408203,
      "learning_rate": 2.7446555819477437e-05,
      "loss": 0.2934,
      "step": 1900
    },
    {
      "epoch": 0.46318289786223277,
      "grad_norm": 8.704279899597168,
      "learning_rate": 2.685273159144893e-05,
      "loss": 0.3029,
      "step": 1950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 6.636017322540283,
      "learning_rate": 2.6258907363420427e-05,
      "loss": 0.2699,
      "step": 2000
    },
    {
      "epoch": 0.48693586698337293,
      "grad_norm": 3.8787734508514404,
      "learning_rate": 2.5665083135391928e-05,
      "loss": 0.3439,
      "step": 2050
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 6.100976467132568,
      "learning_rate": 2.507125890736342e-05,
      "loss": 0.2761,
      "step": 2100
    },
    {
      "epoch": 0.5106888361045131,
      "grad_norm": 2.1108813285827637,
      "learning_rate": 2.4477434679334918e-05,
      "loss": 0.2621,
      "step": 2150
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 3.9259629249572754,
      "learning_rate": 2.3883610451306415e-05,
      "loss": 0.2864,
      "step": 2200
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 4.485057830810547,
      "learning_rate": 2.328978622327791e-05,
      "loss": 0.2667,
      "step": 2250
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 5.841212272644043,
      "learning_rate": 2.2695961995249406e-05,
      "loss": 0.2524,
      "step": 2300
    },
    {
      "epoch": 0.5581947743467933,
      "grad_norm": 5.390171051025391,
      "learning_rate": 2.2102137767220903e-05,
      "loss": 0.2633,
      "step": 2350
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 10.285772323608398,
      "learning_rate": 2.15083135391924e-05,
      "loss": 0.2434,
      "step": 2400
    },
    {
      "epoch": 0.5819477434679335,
      "grad_norm": 2.767355442047119,
      "learning_rate": 2.0914489311163897e-05,
      "loss": 0.2807,
      "step": 2450
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 3.5821330547332764,
      "learning_rate": 2.0320665083135394e-05,
      "loss": 0.2762,
      "step": 2500
    },
    {
      "epoch": 0.6057007125890737,
      "grad_norm": 4.571747303009033,
      "learning_rate": 1.972684085510689e-05,
      "loss": 0.2853,
      "step": 2550
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 10.62077808380127,
      "learning_rate": 1.9133016627078384e-05,
      "loss": 0.2873,
      "step": 2600
    },
    {
      "epoch": 0.6294536817102138,
      "grad_norm": 2.8281688690185547,
      "learning_rate": 1.853919239904988e-05,
      "loss": 0.2994,
      "step": 2650
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 3.017845392227173,
      "learning_rate": 1.7945368171021378e-05,
      "loss": 0.2437,
      "step": 2700
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 5.914938926696777,
      "learning_rate": 1.7351543942992875e-05,
      "loss": 0.2951,
      "step": 2750
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 5.642148494720459,
      "learning_rate": 1.6757719714964372e-05,
      "loss": 0.306,
      "step": 2800
    },
    {
      "epoch": 0.6769596199524941,
      "grad_norm": 1.7524192333221436,
      "learning_rate": 1.616389548693587e-05,
      "loss": 0.2823,
      "step": 2850
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 5.034770965576172,
      "learning_rate": 1.5570071258907366e-05,
      "loss": 0.2785,
      "step": 2900
    },
    {
      "epoch": 0.7007125890736342,
      "grad_norm": 5.624399185180664,
      "learning_rate": 1.497624703087886e-05,
      "loss": 0.2918,
      "step": 2950
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 4.011733531951904,
      "learning_rate": 1.4382422802850357e-05,
      "loss": 0.2664,
      "step": 3000
    },
    {
      "epoch": 0.7244655581947743,
      "grad_norm": 3.313551425933838,
      "learning_rate": 1.3788598574821854e-05,
      "loss": 0.2637,
      "step": 3050
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 4.785347938537598,
      "learning_rate": 1.319477434679335e-05,
      "loss": 0.2788,
      "step": 3100
    },
    {
      "epoch": 0.7482185273159145,
      "grad_norm": 2.8957839012145996,
      "learning_rate": 1.2600950118764846e-05,
      "loss": 0.3089,
      "step": 3150
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 2.743889570236206,
      "learning_rate": 1.2007125890736343e-05,
      "loss": 0.2995,
      "step": 3200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 2.9429173469543457,
      "learning_rate": 1.1413301662707838e-05,
      "loss": 0.2408,
      "step": 3250
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 8.107160568237305,
      "learning_rate": 1.0819477434679335e-05,
      "loss": 0.2561,
      "step": 3300
    },
    {
      "epoch": 0.7957244655581948,
      "grad_norm": 9.058357238769531,
      "learning_rate": 1.0225653206650832e-05,
      "loss": 0.2561,
      "step": 3350
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 4.571059703826904,
      "learning_rate": 9.63182897862233e-06,
      "loss": 0.2737,
      "step": 3400
    },
    {
      "epoch": 0.8194774346793349,
      "grad_norm": 9.0098876953125,
      "learning_rate": 9.038004750593825e-06,
      "loss": 0.2946,
      "step": 3450
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 9.363811492919922,
      "learning_rate": 8.444180522565321e-06,
      "loss": 0.2671,
      "step": 3500
    },
    {
      "epoch": 0.8432304038004751,
      "grad_norm": 1.5169771909713745,
      "learning_rate": 7.850356294536817e-06,
      "loss": 0.2874,
      "step": 3550
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.8003969192504883,
      "learning_rate": 7.256532066508314e-06,
      "loss": 0.2626,
      "step": 3600
    },
    {
      "epoch": 0.8669833729216152,
      "grad_norm": 8.036463737487793,
      "learning_rate": 6.662707838479811e-06,
      "loss": 0.2776,
      "step": 3650
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 2.0252230167388916,
      "learning_rate": 6.068883610451306e-06,
      "loss": 0.2683,
      "step": 3700
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 6.529168128967285,
      "learning_rate": 5.475059382422803e-06,
      "loss": 0.278,
      "step": 3750
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 3.91092586517334,
      "learning_rate": 4.881235154394299e-06,
      "loss": 0.2675,
      "step": 3800
    },
    {
      "epoch": 0.9144893111638955,
      "grad_norm": 8.224502563476562,
      "learning_rate": 4.287410926365796e-06,
      "loss": 0.254,
      "step": 3850
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 2.4143991470336914,
      "learning_rate": 3.6935866983372922e-06,
      "loss": 0.2426,
      "step": 3900
    },
    {
      "epoch": 0.9382422802850356,
      "grad_norm": 3.363908052444458,
      "learning_rate": 3.099762470308789e-06,
      "loss": 0.2598,
      "step": 3950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 3.7216882705688477,
      "learning_rate": 2.505938242280285e-06,
      "loss": 0.2507,
      "step": 4000
    }
  ],
  "logging_steps": 50,
  "max_steps": 4210,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4224347996160000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
